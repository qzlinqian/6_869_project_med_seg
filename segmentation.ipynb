{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1RInkdjt2rwEA67LXydJKIIuBzjknlhzr",
      "authorship_tag": "ABX9TyM+goDyvyZI1ZY0+3ZZ+adL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qzlinqian/6_869_project_med_seg/blob/main/segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Load data and basic setup"
      ],
      "metadata": {
        "id": "5EIFwPD9dK02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WZnyzh1HdJsv"
      },
      "outputs": [],
      "source": [
        "use_gdrive = True  # want to use data in my google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  data_dir = \"/content/drive/MyDrive/data\"\n",
        "else:\n",
        "  data_dir = \"./data\"\n",
        "\n",
        "datasets_dir = data_dir + '/Task03_Liver'\n",
        "\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "\n",
        "training_imgs_dir = datasets_dir + '/imagesTr'\n",
        "training_labels_dir = datasets_dir + '/labelsTr'\n",
        "test_imgs_dir = datasets_dir + '/imagesTs'\n",
        "two_d_imgs_dir = datasets_dir + '/2d/images/'\n",
        "two_d_labels_dir = datasets_dir + '/2d/labels/'\n"
      ],
      "metadata": {
        "id": "6HXa0biOdhOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678b39be-5b36-4735-dda5-a5612d3557bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib  # to read .nii.gz files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SKhXrtzn8VUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To clone from repo"
      ],
      "metadata": {
        "id": "PZEWs-qT0ONM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = 'qzlinqian'\n",
        "repository = '6_869_project_med_seg'\n",
        "git_token =  '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'"
      ],
      "metadata": {
        "id": "ReimNrUbYofc"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{git_token}@github.com/{username}/{repository} temp\n",
        "%cp -r temp/* .\n",
        "%rm -rf temp\n",
        "%rm segmentation.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDtwWHdQZK05",
        "outputId": "aa21f051-ce9f-41a5-cc6d-65e5b29501f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dense_unet import DenseUNet\n",
        "\n",
        "pretrained_encoder_uri = 'https://download.pytorch.org/models/densenet121-a639ec97.pth'\n",
        "num_output_classes = 3\n",
        "model = DenseUNet(num_output_classes, downsample=True, pretrained_encoder_uri=pretrained_encoder_uri)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBVuondPbDDb",
        "outputId": "2d8056de-05f6-4d15-8e03-ab81b4b56a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initialize a new model"
      ],
      "metadata": {
        "id": "LNKsnZ6rVQYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import copy\n",
        "import PIL \n",
        "  \n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU!\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only\")\n",
        "    print(\"You may want to try to use the GPU in Google Colab by clicking in:\")\n",
        "    print(\"Runtime > Change Runtime type > Hardware accelerator > GPU.\")"
      ],
      "metadata": {
        "id": "2LskMUNeWFTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb01d4d2-da67-4e00-f1ff-cea0ddcb52ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from imutils import paths"
      ],
      "metadata": {
        "id": "wbYGA7Jy1MiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define parameters"
      ],
      "metadata": {
        "id": "s9E-4xbX0YH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 512\n",
        "image_height = 512\n",
        "threshold = 0.5"
      ],
      "metadata": {
        "id": "yp0HPTfIsZXg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "U1LfthTHzdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2"
      ],
      "metadata": {
        "id": "hbiayEAkxLLe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for reference\n",
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, tr_image_paths, tr_label_paths, ts_image_paths, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.tr_image_paths = tr_image_paths\n",
        "    self.tr_label_paths = tr_label_paths\n",
        "    self.ts_image_paths = ts_image_paths\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "    return 120\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "    tr_image_path = self.tr_image_paths + '/liver_' + str(idx) + '.nii.gz'\n",
        "    tr_label_path = self.tr_label_paths + '/liver_' + str(idx) + '.nii.gz'\n",
        "\t\t# load the image from disk, swap its channels from BGR to RGB,\n",
        "\t\t# and read the associated mask from disk in grayscale mode\n",
        "    image = nib.load(tr_image_path).get_fdata().squeeze()\n",
        "    label = nib.load(tr_label_path).get_fdata().squeeze()\n",
        "\t\t# check to see if we are applying any transformations\n",
        "    if self.transforms is not None:\n",
        "\t\t\t# apply the transformations to both image and its mask\n",
        "      image = self.transforms(image)\n",
        "      label = self.transforms(label)\n",
        "\t\t# return a tuple of the image and its mask\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "sWUcCnMp18fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This was just for test\n",
        "class Test2DDataset(Dataset):\n",
        "  def __init__(self, tr_image_paths, tr_label_paths, ts_image_paths, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.tr_image_paths = tr_image_paths\n",
        "    self.tr_label_paths = tr_label_paths\n",
        "    self.ts_image_paths = ts_image_paths\n",
        "    self.transforms = transforms\n",
        "    \n",
        "    tr_image_path = self.tr_image_paths + '/liver_2.nii.gz'\n",
        "    tr_label_path = self.tr_label_paths + '/liver_2.nii.gz'\n",
        "    # load the image from disk, swap its channels from BGR to RGB,\n",
        "    # and read the associated mask from disk in grayscale mode\n",
        "    self.images = nib.load(tr_image_path).get_fdata().squeeze()\n",
        "    self.labels = nib.load(tr_label_path).get_fdata().squeeze()\n",
        "    for i in range(2):\n",
        "      tr_image_path = self.tr_image_paths + '/liver_' + str(i) + '.nii.gz'\n",
        "      tr_label_path = self.tr_label_paths + '/liver_' + str(i) + '.nii.gz'\n",
        "      # load the image from disk, swap its channels from BGR to RGB,\n",
        "      # and read the associated mask from disk in grayscale mode\n",
        "      self.images = np.concatenate([self.images, nib.load(tr_image_path).get_fdata().squeeze()], axis=2)\n",
        "      self.labels = np.concatenate([self.labels, nib.load(tr_label_path).get_fdata().squeeze()], axis=2)\n",
        "\n",
        "  def __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "    return self.images.shape[2]\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "\t\t# check to see if we are applying any transformations\n",
        "    image = self.images[:,:,idx]\n",
        "    label = self.labels[:,:,idx]\n",
        "    # print(image.shape)\n",
        "    # if self.transforms is not None:\n",
        "\t\t\t# apply the transformations to both image and its mask\n",
        "      # image = torch.from_numpy(self.transforms(image))\n",
        "      # label = torch.from_numpy(self.transforms(label))\n",
        "    image = torch.from_numpy(image).unsqueeze(dim=0).float()\n",
        "    label = torch.from_numpy(label).long()\n",
        "\t\t# return a tuple of the image and its mask\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "FlPpV9Q91UPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoDimImageDataset(Dataset):\n",
        "  def __init__(self, indices, tr_image_path, tr_label_path, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.indices = indices\n",
        "    self.tr_image_path = tr_image_path\n",
        "    self.tr_label_path = tr_label_path\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data_index = self.indices[idx]\n",
        "    image = torch.from_numpy(np.load(self.tr_image_path + str(data_index) + '.npy')).unsqueeze(dim=0).float()\n",
        "    label = torch.from_numpy(np.load(self.tr_label_path + str(data_index) + '.npy')).long()\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "kVn8dZF72c14"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, inChannels, outChannels):\n",
        "    super().__init__()\n",
        "    # store the convolution and RELU layers\n",
        "    self.conv1 = nn.Conv2d(inChannels, outChannels, 3)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(outChannels, outChannels, 3)\n",
        "  def forward(self, x):\n",
        "    # apply CONV => RELU => CONV block to the inputs and return it\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, channels=(1, 4, 16, 32, 64)):\n",
        "    super().__init__()\n",
        "    # store the encoder blocks and maxpooling layer\n",
        "    self.encBlocks = nn.ModuleList(\n",
        "      [Block(channels[i], channels[i + 1])\n",
        "        for i in range(len(channels) - 1)])\n",
        "    self.pool = nn.MaxPool2d(2)\n",
        "  def forward(self, x):\n",
        "    # initialize an empty list to store the intermediate outputs\n",
        "    blockOutputs = []\n",
        "    # loop through the encoder blocks\n",
        "    for block in self.encBlocks:\n",
        "      # pass the inputs through the current encoder block, store\n",
        "      # the outputs, and then apply maxpooling on the output\n",
        "      x = block(x)\n",
        "      blockOutputs.append(x)\n",
        "      x = self.pool(x)\n",
        "    # return the list containing the intermediate outputs\n",
        "    return blockOutputs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, channels=(64, 32, 16, 4)):\n",
        "    super().__init__()\n",
        "    # initialize the number of channels, upsampler blocks, and\n",
        "    # decoder blocks\n",
        "    self.channels = channels\n",
        "    self.upconvs = nn.ModuleList(\n",
        "      [nn.ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
        "        for i in range(len(channels) - 1)])\n",
        "    self.dec_blocks = nn.ModuleList(\n",
        "      [Block(channels[i], channels[i + 1])\n",
        "        for i in range(len(channels) - 1)])\n",
        "  def forward(self, x, encFeatures):\n",
        "    # loop through the number of channels\n",
        "    for i in range(len(self.channels) - 1):\n",
        "      # pass the inputs through the upsampler blocks\n",
        "      x = self.upconvs[i](x)\n",
        "      # crop the current features from the encoder blocks,\n",
        "      # concatenate them with the current upsampled features,\n",
        "      # and pass the concatenated output through the current\n",
        "      # decoder block\n",
        "      encFeat = self.crop(encFeatures[i], x)\n",
        "      x = torch.cat([x, encFeat], dim=1)\n",
        "      x = self.dec_blocks[i](x)\n",
        "    # return the final decoder output\n",
        "    return x\n",
        "  def crop(self, encFeatures, x):\n",
        "    # grab the dimensions of the inputs, and crop the encoder\n",
        "    # features to match the dimensions\n",
        "    (_, _, H, W) = x.shape\n",
        "    encFeatures = transforms.CenterCrop([H, W])(encFeatures)\n",
        "    # return the cropped features\n",
        "    return encFeatures"
      ],
      "metadata": {
        "id": "fpZRTezxza5S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, encChannels=(1, 4, 8, 16, 32),\n",
        "      decChannels=(32, 16, 8, 4),\n",
        "      nbClasses=3, retainDim=True,\n",
        "      outSize=(image_width, image_height)):\n",
        "    super().__init__()\n",
        "    # initialize the encoder and decoder\n",
        "    self.encoder = Encoder(encChannels)\n",
        "    self.decoder = Decoder(decChannels)\n",
        "    # initialize the regression head and store the class variables\n",
        "    self.classifier = nn.Conv2d(decChannels[-1], nbClasses, 1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.retainDim = retainDim\n",
        "    self.outSize = outSize\n",
        "\n",
        "  def forward(self, x):\n",
        "    # grab the features from the encoder\n",
        "    encFeatures = self.encoder(x)\n",
        "    # pass the encoder features through decoder making sure that\n",
        "    # their dimensions are suited for concatenation\n",
        "    decFeatures = self.decoder(encFeatures[::-1][0],\n",
        "      encFeatures[::-1][1:])\n",
        "    # pass the decoder features through the regression head to\n",
        "    # obtain the segmentation mask\n",
        "    map = self.classifier(decFeatures)\n",
        "    # check to see if we are retaining the original output\n",
        "    # dimensions and if so, then resize the output to match them\n",
        "    if self.retainDim:\n",
        "      map = nn.functional.interpolate(map, self.outSize)\n",
        "    # return the segmentation map\n",
        "    return self.softmax(map)"
      ],
      "metadata": {
        "id": "6exwE2Wi0qJ-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training"
      ],
      "metadata": {
        "id": "AnNdIWwA1JQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "# define transformations\n",
        "transforms_def = transforms.Compose([transforms.ToPILImage(),\n",
        "  transforms.Resize((image_width, image_height)),\n",
        "  transforms.ToTensor()])\n",
        "# create the train and test datasets\n",
        "indices = np.random.choice(range(7190), size=(1000), replace=False)\n",
        "train_ds = TwoDimImageDataset(indices[:800], two_d_imgs_dir, two_d_labels_dir, transforms)\n",
        "test_ds = TwoDimImageDataset(indices[800:], two_d_imgs_dir, two_d_labels_dir, transforms)\n",
        "print(f\"[INFO] found {len(train_ds)} examples in the training set...\")\n",
        "print(f\"[INFO] found {len(test_ds)} examples in the test set...\")\n",
        "# create the training and test data loaders\n",
        "trainLoader = DataLoader(train_ds, shuffle=True,\n",
        "  batch_size=batch_size, pin_memory=True,\n",
        "  num_workers=os.cpu_count())\n",
        "testLoader = DataLoader(test_ds, shuffle=False,\n",
        "\tbatch_size=batch_size, pin_memory=True,\n",
        "\tnum_workers=os.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbfebRJu1Ver",
        "outputId": "9d628339-bd38-4a7c-8839-79e6bfb31e26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] found 800 examples in the training set...\n",
            "[INFO] found 200 examples in the test set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0005\n",
        "# initialize our UNet model\n",
        "unet = UNet().to(device)\n",
        "# initialize loss function and optimizer\n",
        "opt = optim.SGD(unet.parameters(), lr=learning_rate, momentum=0.9)\n",
        "# calculate steps per epoch for training and test set\n",
        "train_steps = len(train_ds) // batch_size\n",
        "test_steps = len(test_ds) // batch_size\n",
        "# initialize a dictionary to store training history\n",
        "H = {\"train_loss\": [], \"test_loss\": []}"
      ],
      "metadata": {
        "id": "yp6UCXU1jgHh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over epochs\n",
        "num_epochs = 30\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "best_acc = 0.0\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "epoch = 0\n",
        "for e in tqdm(range(num_epochs)):\n",
        "  # set the model in training mode\n",
        "  unet.train()\n",
        "  # initialize the total training and validation loss\n",
        "  total_train_loss = 0\n",
        "  total_test_loss = 0\n",
        "  # loop over the training set\n",
        "  with torch.set_grad_enabled(True):\n",
        "    train_acc = 0\n",
        "    test_acc = 0\n",
        "    for i, map in enumerate(trainLoader):\n",
        "      # send the input to the device\n",
        "      x, y = map['image'].to(device), map['label'].to(device).squeeze()\n",
        "      # perform a forward pass and calculate the training loss\n",
        "      prob = unet(x)\n",
        "      loss = loss_function(prob, y)\n",
        "      _, preds = torch.max(prob, 1)\n",
        "      # first, zero out any previously accumulated gradients, then\n",
        "      # perform backpropagation, and then update model parameters\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      # add the loss to the total training loss so far\n",
        "      total_train_loss += loss\n",
        "      train_acc += torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])\n",
        "  # switch off autograd\n",
        "  with torch.set_grad_enabled(False):\n",
        "    # set the model in evaluation mode\n",
        "    unet.eval()\n",
        "    # loop over the validation set\n",
        "    for map in testLoader:\n",
        "      # send the input to the device\n",
        "      x, y = map['image'].to(device), map['label'].to(device).squeeze()\n",
        "      # make the predictions and calculate the validation loss\n",
        "      prob = unet(x)\n",
        "      total_test_loss += loss_function(prob, y)\n",
        "      _, preds = torch.max(prob, 1)\n",
        "      test_acc += torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])\n",
        "  # calculate the average training and validation loss\n",
        "  avg_train_loss = total_train_loss / train_steps\n",
        "  avg_test_loss = total_test_loss / test_steps\n",
        "  train_acc /= train_steps\n",
        "  test_acc /= test_steps\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    best_model_wts = copy.deepcopy(unet.state_dict())\n",
        "    epoch = e\n",
        "  train_loss_history.append(avg_test_loss)\n",
        "  val_loss_history.append(avg_test_loss)\n",
        "  # update our training history\n",
        "  # H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
        "  # H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
        "  # print the model training and validation information\n",
        "  print(\"[INFO] EPOCH: {}/{}\".format(e + 1, num_epochs))\n",
        "  print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
        "    avg_train_loss, avg_test_loss))\n",
        "  print(\"Train acc: {:.6f}, Test acc: {:.4f}\".format(\n",
        "    train_acc, test_acc))\n",
        "# display the total time needed to perform the training\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "  endTime - startTime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeyvWtHu4A2g",
        "outputId": "a64cc9ea-42eb-4346-abd6-2f50441673dc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training the network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1/30 [00:08<04:15,  8.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 1/30\n",
            "Train loss: 1.116198, Test loss: 1.1694\n",
            "Train acc: 0.555558, Test acc: 1.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [00:17<04:01,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 2/30\n",
            "Train loss: 0.995256, Test loss: 1.1509\n",
            "Train acc: 0.873241, Test acc: 1.0321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:25<03:52,  8.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 3/30\n",
            "Train loss: 0.975893, Test loss: 1.1207\n",
            "Train acc: 0.889787, Test acc: 1.0442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [00:34<03:42,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 4/30\n",
            "Train loss: 0.823749, Test loss: 0.8020\n",
            "Train acc: 0.900821, Test acc: 1.0591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [00:42<03:33,  8.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 5/30\n",
            "Train loss: 0.666477, Test loss: 0.7640\n",
            "Train acc: 0.908301, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [00:51<03:25,  8.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 6/30\n",
            "Train loss: 0.652033, Test loss: 0.7577\n",
            "Train acc: 0.908481, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [00:59<03:15,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 7/30\n",
            "Train loss: 0.648566, Test loss: 0.7552\n",
            "Train acc: 0.908492, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [01:08<03:06,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 8/30\n",
            "Train loss: 0.646986, Test loss: 0.7539\n",
            "Train acc: 0.908495, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [01:16<02:58,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 9/30\n",
            "Train loss: 0.646076, Test loss: 0.7531\n",
            "Train acc: 0.908497, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [01:25<02:51,  8.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 10/30\n",
            "Train loss: 0.645487, Test loss: 0.7525\n",
            "Train acc: 0.908498, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [01:33<02:41,  8.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 11/30\n",
            "Train loss: 0.645073, Test loss: 0.7521\n",
            "Train acc: 0.908499, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [01:42<02:32,  8.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 12/30\n",
            "Train loss: 0.644772, Test loss: 0.7518\n",
            "Train acc: 0.908499, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 13/30 [01:51<02:24,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 13/30\n",
            "Train loss: 0.644541, Test loss: 0.7516\n",
            "Train acc: 0.908499, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 14/30 [01:59<02:15,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 14/30\n",
            "Train loss: 0.644360, Test loss: 0.7514\n",
            "Train acc: 0.908499, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 15/30 [02:08<02:07,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 15/30\n",
            "Train loss: 0.644214, Test loss: 0.7513\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [02:16<01:59,  8.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 16/30\n",
            "Train loss: 0.644094, Test loss: 0.7511\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 17/30 [02:25<01:50,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 17/30\n",
            "Train loss: 0.643993, Test loss: 0.7510\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 18/30 [02:33<01:42,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 18/30\n",
            "Train loss: 0.643909, Test loss: 0.7509\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [02:42<01:33,  8.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 19/30\n",
            "Train loss: 0.643836, Test loss: 0.7509\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 67%|██████▋   | 20/30 [02:50<01:25,  8.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 20/30\n",
            "Train loss: 0.643773, Test loss: 0.7508\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 70%|███████   | 21/30 [02:59<01:16,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 21/30\n",
            "Train loss: 0.643718, Test loss: 0.7507\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 73%|███████▎  | 22/30 [03:08<01:09,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 22/30\n",
            "Train loss: 0.643669, Test loss: 0.7507\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "AssertionError: can only test a child process\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 77%|███████▋  | 23/30 [03:16<01:00,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 23/30\n",
            "Train loss: 0.643626, Test loss: 0.7506\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "AssertionError: can only test a child process\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 80%|████████  | 24/30 [03:25<00:51,  8.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 24/30\n",
            "Train loss: 0.643588, Test loss: 0.7506\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 83%|████████▎ | 25/30 [03:34<00:43,  8.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 25/30\n",
            "Train loss: 0.643553, Test loss: 0.7506\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 87%|████████▋ | 26/30 [03:42<00:34,  8.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 26/30\n",
            "Train loss: 0.643522, Test loss: 0.7505\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 90%|█████████ | 27/30 [03:51<00:26,  8.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 27/30\n",
            "Train loss: 0.643494, Test loss: 0.7505\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    if w.is_alive():\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 93%|█████████▎| 28/30 [04:00<00:17,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 28/30\n",
            "Train loss: 0.643468, Test loss: 0.7505\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 97%|█████████▋| 29/30 [04:09<00:08,  8.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 29/30\n",
            "Train loss: 0.643444, Test loss: 0.7504\n",
            "Train acc: 0.908500, Test acc: 1.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8020bcb200>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "100%|██████████| 30/30 [04:18<00:00,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 30/30\n",
            "Train loss: 0.643423, Test loss: 0.7504\n",
            "Train acc: 0.908500, Test acc: 1.0601\n",
            "[INFO] total time taken to train the model: 258.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpjvecU_cf3O",
        "outputId": "68c9830d-c553-40fd-89cd-6044bbbacf4c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9034, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = './models'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(best_model_wts, os.path.join(save_dir, 'weights_best_val_acc.pt'))\n",
        "torch.save(unet.state_dict(), os.path.join(save_dir, 'weights_last.pt'.format(epoch)))"
      ],
      "metadata": {
        "id": "KPDuXrcIUZUY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{git_token}@github.com/{username}/{repository} temp\n",
        "%cp -rf models temp\n",
        "%cd temp\n",
        "\n",
        "!git config --global user.email \"qzlinqian@126.com\"\n",
        "!git config --global user.name \"Qian Lin\"\n",
        "\n",
        "!git add .\n",
        "!git commit -m\"add 2d model\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9drqK8bd50S",
        "outputId": "455c5acb-1a77-4470-8570-2d72b1331614"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "/content/temp\n",
            "[main e57e5f3] add 2d model\n",
            " 2 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 models/weights_best_val_acc.pt\n",
            " create mode 100644 models/weights_last.pt\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 131.63 KiB | 11.97 MiB/s, done.\n",
            "Total 5 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 1 local object.\u001b[K\n",
            "To https://github.com/qzlinqian/6_869_project_med_seg\n",
            "   dc2a3af..e57e5f3  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%rm -rf temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCYeGUP5f3kc",
        "outputId": "9912db3b-7862-4441-bb03-43002104243d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "r3548tMFFFY3"
      }
    }
  ]
}