{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1RInkdjt2rwEA67LXydJKIIuBzjknlhzr",
      "authorship_tag": "ABX9TyMC71+he08XUpgFrcwNWHgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qzlinqian/6_869_project_med_seg/blob/main/segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Load data and basic setup"
      ],
      "metadata": {
        "id": "5EIFwPD9dK02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WZnyzh1HdJsv"
      },
      "outputs": [],
      "source": [
        "use_gdrive = True  # want to use data in my google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  data_dir = \"/content/drive/MyDrive/data\"\n",
        "else:\n",
        "  data_dir = \"./data\"\n",
        "\n",
        "datasets_dir = data_dir + '/Task03_Liver'\n",
        "\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "\n",
        "training_imgs_dir = datasets_dir + '/imagesTr'\n",
        "training_labels_dir = datasets_dir + '/labelsTr'\n",
        "test_imgs_dir = datasets_dir + '/imagesTs'\n",
        "two_d_imgs_dir = datasets_dir + '/2d/images/'\n",
        "two_d_labels_dir = datasets_dir + '/2d/labels/'\n"
      ],
      "metadata": {
        "id": "6HXa0biOdhOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8e5d27-38a7-4d3c-8868-88cf376c85b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib  # to read .nii.gz files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SKhXrtzn8VUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To clone from repo"
      ],
      "metadata": {
        "id": "PZEWs-qT0ONM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = 'qzlinqian'\n",
        "repository = '6_869_project_med_seg'\n",
        "git_token =  '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'"
      ],
      "metadata": {
        "id": "ReimNrUbYofc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{git_token}@github.com/{username}/{repository} temp\n",
        "%cp -r temp/* .\n",
        "%rm -rf temp\n",
        "%rm segmentation.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDtwWHdQZK05",
        "outputId": "aa21f051-ce9f-41a5-cc6d-65e5b29501f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dense_unet import DenseUNet\n",
        "\n",
        "pretrained_encoder_uri = 'https://download.pytorch.org/models/densenet121-a639ec97.pth'\n",
        "num_output_classes = 3\n",
        "model = DenseUNet(num_output_classes, downsample=True, pretrained_encoder_uri=pretrained_encoder_uri)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBVuondPbDDb",
        "outputId": "2d8056de-05f6-4d15-8e03-ab81b4b56a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initialize a new model"
      ],
      "metadata": {
        "id": "LNKsnZ6rVQYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import copy\n",
        "import PIL \n",
        "  \n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU!\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only\")\n",
        "    print(\"You may want to try to use the GPU in Google Colab by clicking in:\")\n",
        "    print(\"Runtime > Change Runtime type > Hardware accelerator > GPU.\")"
      ],
      "metadata": {
        "id": "2LskMUNeWFTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63cf820-7aee-4ae4-f1d3-8ed488a59c00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from imutils import paths"
      ],
      "metadata": {
        "id": "wbYGA7Jy1MiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define parameters"
      ],
      "metadata": {
        "id": "s9E-4xbX0YH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 512\n",
        "image_height = 512\n",
        "threshold = 0.5"
      ],
      "metadata": {
        "id": "yp0HPTfIsZXg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "U1LfthTHzdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2"
      ],
      "metadata": {
        "id": "hbiayEAkxLLe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for reference\n",
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, tr_image_paths, tr_label_paths, ts_image_paths, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.tr_image_paths = tr_image_paths\n",
        "    self.tr_label_paths = tr_label_paths\n",
        "    self.ts_image_paths = ts_image_paths\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "    return 120\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "    tr_image_path = self.tr_image_paths + '/liver_' + str(idx) + '.nii.gz'\n",
        "    tr_label_path = self.tr_label_paths + '/liver_' + str(idx) + '.nii.gz'\n",
        "\t\t# load the image from disk, swap its channels from BGR to RGB,\n",
        "\t\t# and read the associated mask from disk in grayscale mode\n",
        "    image = nib.load(tr_image_path).get_fdata().squeeze()\n",
        "    label = nib.load(tr_label_path).get_fdata().squeeze()\n",
        "\t\t# check to see if we are applying any transformations\n",
        "    if self.transforms is not None:\n",
        "\t\t\t# apply the transformations to both image and its mask\n",
        "      image = self.transforms(image)\n",
        "      label = self.transforms(label)\n",
        "\t\t# return a tuple of the image and its mask\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "sWUcCnMp18fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This was just for test\n",
        "class Test2DDataset(Dataset):\n",
        "  def __init__(self, tr_image_paths, tr_label_paths, ts_image_paths, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.tr_image_paths = tr_image_paths\n",
        "    self.tr_label_paths = tr_label_paths\n",
        "    self.ts_image_paths = ts_image_paths\n",
        "    self.transforms = transforms\n",
        "    \n",
        "    tr_image_path = self.tr_image_paths + '/liver_2.nii.gz'\n",
        "    tr_label_path = self.tr_label_paths + '/liver_2.nii.gz'\n",
        "    # load the image from disk, swap its channels from BGR to RGB,\n",
        "    # and read the associated mask from disk in grayscale mode\n",
        "    self.images = nib.load(tr_image_path).get_fdata().squeeze()\n",
        "    self.labels = nib.load(tr_label_path).get_fdata().squeeze()\n",
        "    for i in range(2):\n",
        "      tr_image_path = self.tr_image_paths + '/liver_' + str(i) + '.nii.gz'\n",
        "      tr_label_path = self.tr_label_paths + '/liver_' + str(i) + '.nii.gz'\n",
        "      # load the image from disk, swap its channels from BGR to RGB,\n",
        "      # and read the associated mask from disk in grayscale mode\n",
        "      self.images = np.concatenate([self.images, nib.load(tr_image_path).get_fdata().squeeze()], axis=2)\n",
        "      self.labels = np.concatenate([self.labels, nib.load(tr_label_path).get_fdata().squeeze()], axis=2)\n",
        "\n",
        "  def __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "    return self.images.shape[2]\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "\t\t# check to see if we are applying any transformations\n",
        "    image = self.images[:,:,idx]\n",
        "    label = self.labels[:,:,idx]\n",
        "    # print(image.shape)\n",
        "    image = torch.from_numpy(image).unsqueeze(dim=0).float()\n",
        "    label = torch.from_numpy(label).long()\n",
        "    if self.transforms is not None:\n",
        "\t\t\t#apply the transformations to both image and its mask\n",
        "      image = self.transforms(image)\n",
        "      label = self.transforms(label)\n",
        "\t\t# return a tuple of the image and its mask\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "FlPpV9Q91UPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoDimImageDataset(Dataset):\n",
        "  def __init__(self, indices, tr_image_path, tr_label_path, transforms=None):\n",
        "\t\t# store the image and label filepaths\n",
        "    self.indices = indices\n",
        "    self.tr_image_path = tr_image_path\n",
        "    self.tr_label_path = tr_label_path\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data_index = self.indices[idx]\n",
        "    image = torch.from_numpy(np.load(self.tr_image_path + str(data_index) + '.npy')).unsqueeze(dim=0).float()\n",
        "    label = torch.from_numpy(np.load(self.tr_label_path + str(data_index) + '.npy')).long()\n",
        "    return {'image': image, 'label': label}"
      ],
      "metadata": {
        "id": "kVn8dZF72c14"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, inChannels, outChannels):\n",
        "    super().__init__()\n",
        "    # store the convolution and RELU layers\n",
        "    self.conv1 = nn.Conv2d(inChannels, outChannels, 3)\n",
        "    self.batch1 = nn.BatchNorm2d(outChannels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(outChannels, outChannels, 3)\n",
        "    self.batch1 = nn.BatchNorm2d(outChannels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "  def forward(self, x):\n",
        "    # apply CONV => RELU => CONV block to the inputs and return it\n",
        "    x = self.conv1(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, channels=(1, 4, 16, 32, 64)):\n",
        "    super().__init__()\n",
        "    # store the encoder blocks and maxpooling layer\n",
        "    self.encBlocks = nn.ModuleList(\n",
        "      [Block(channels[i], channels[i + 1])\n",
        "        for i in range(len(channels) - 1)])\n",
        "    self.pool = nn.MaxPool2d(2)\n",
        "  def forward(self, x):\n",
        "    # initialize an empty list to store the intermediate outputs\n",
        "    blockOutputs = []\n",
        "    # loop through the encoder blocks\n",
        "    for block in self.encBlocks:\n",
        "      # pass the inputs through the current encoder block, store\n",
        "      # the outputs, and then apply maxpooling on the output\n",
        "      x = block(x)\n",
        "      blockOutputs.append(x)\n",
        "      x = self.pool(x)\n",
        "    # return the list containing the intermediate outputs\n",
        "    return blockOutputs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, channels=(64, 32, 16, 4)):\n",
        "    super().__init__()\n",
        "    # initialize the number of channels, upsampler blocks, and\n",
        "    # decoder blocks\n",
        "    self.channels = channels\n",
        "    self.upconvs = nn.ModuleList(\n",
        "      [nn.ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
        "        for i in range(len(channels) - 1)])\n",
        "    self.dec_blocks = nn.ModuleList(\n",
        "      [Block(channels[i], channels[i + 1])\n",
        "        for i in range(len(channels) - 1)])\n",
        "  def forward(self, x, encFeatures):\n",
        "    # loop through the number of channels\n",
        "    for i in range(len(self.channels) - 1):\n",
        "      # pass the inputs through the upsampler blocks\n",
        "      x = self.upconvs[i](x)\n",
        "      # crop the current features from the encoder blocks,\n",
        "      # concatenate them with the current upsampled features,\n",
        "      # and pass the concatenated output through the current\n",
        "      # decoder block\n",
        "      encFeat = self.crop(encFeatures[i], x)\n",
        "      x = torch.cat([x, encFeat], dim=1)\n",
        "      x = self.dec_blocks[i](x)\n",
        "    # return the final decoder output\n",
        "    return x\n",
        "  def crop(self, encFeatures, x):\n",
        "    # grab the dimensions of the inputs, and crop the encoder\n",
        "    # features to match the dimensions\n",
        "    (_, _, H, W) = x.shape\n",
        "    encFeatures = transforms.CenterCrop([H, W])(encFeatures)\n",
        "    # return the cropped features\n",
        "    return encFeatures"
      ],
      "metadata": {
        "id": "fpZRTezxza5S"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, encChannels=(1, 4, 8, 16, 32),\n",
        "      decChannels=(32, 16, 8, 4),\n",
        "      nbClasses=3, retainDim=True,\n",
        "      outSize=(image_width, image_height)):\n",
        "    super().__init__()\n",
        "    # initialize the encoder and decoder\n",
        "    self.encoder = Encoder(encChannels)\n",
        "    self.decoder = Decoder(decChannels)\n",
        "    # initialize the regression head and store the class variables\n",
        "    self.classifier = nn.Conv2d(decChannels[-1], nbClasses, 1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.retainDim = retainDim\n",
        "    self.outSize = outSize\n",
        "\n",
        "  def forward(self, x):\n",
        "    # grab the features from the encoder\n",
        "    encFeatures = self.encoder(x)\n",
        "    # pass the encoder features through decoder making sure that\n",
        "    # their dimensions are suited for concatenation\n",
        "    decFeatures = self.decoder(encFeatures[::-1][0],\n",
        "      encFeatures[::-1][1:])\n",
        "    # pass the decoder features through the regression head to\n",
        "    # obtain the segmentation mask\n",
        "    map = self.classifier(decFeatures)\n",
        "    # check to see if we are retaining the original output\n",
        "    # dimensions and if so, then resize the output to match them\n",
        "    if self.retainDim:\n",
        "      map = nn.functional.interpolate(map, self.outSize)\n",
        "    # return the segmentation map\n",
        "    return self.softmax(map)"
      ],
      "metadata": {
        "id": "6exwE2Wi0qJ-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training"
      ],
      "metadata": {
        "id": "AnNdIWwA1JQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "# define transformations\n",
        "transforms_def = transforms.Compose([transforms.ToPILImage(),\n",
        "  transforms.Resize((image_width, image_height)),\n",
        "  transforms.ToTensor()])\n",
        "# create the train and test datasets\n",
        "indices = np.random.choice(range(7190), size=(1000), replace=False)\n",
        "train_ds = TwoDimImageDataset(indices[:800], two_d_imgs_dir, two_d_labels_dir, transforms)\n",
        "test_ds = TwoDimImageDataset(indices[800:], two_d_imgs_dir, two_d_labels_dir, transforms)\n",
        "print(f\"[INFO] found {len(train_ds)} examples in the training set...\")\n",
        "print(f\"[INFO] found {len(test_ds)} examples in the test set...\")\n",
        "# create the training and test data loaders\n",
        "trainLoader = DataLoader(train_ds, shuffle=True,\n",
        "  batch_size=batch_size, pin_memory=True,\n",
        "  num_workers=os.cpu_count())\n",
        "testLoader = DataLoader(test_ds, shuffle=False,\n",
        "\tbatch_size=batch_size, pin_memory=True,\n",
        "\tnum_workers=os.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbfebRJu1Ver",
        "outputId": "fd98e80c-5589-450a-a625-e33f97f125f1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] found 800 examples in the training set...\n",
            "[INFO] found 200 examples in the test set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "# initialize our UNet model\n",
        "unet = UNet().to(device)\n",
        "# initialize loss function and optimizer\n",
        "opt = optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "# calculate steps per epoch for training and test set\n",
        "train_steps = len(train_ds) // batch_size\n",
        "test_steps = len(test_ds) // batch_size\n",
        "# initialize a dictionary to store training history\n",
        "H = {\"train_loss\": [], \"test_loss\": []}"
      ],
      "metadata": {
        "id": "yp6UCXU1jgHh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.tensor([0.1, 0.9]).to(device)\n",
        "loss_function = nn.CrossEntropyLoss(weight=weight, reduction='sum')\n",
        "# def my_loss_function(output, labels):\n",
        "#   selected_output = torch.reshape(output, (output.shape[0], output.shape[1], output.shape[2]*output.shape[3]))\n",
        "#   selected_output = torch.transpose(selected_output, 0, 1)\n",
        "#   selected_labels = torch.reshape(labels, (labels.shape[0], labels.shape[1]*output.shape[2]))\n",
        "#   selected_output = selected_output[:,torch.where(selected_labels > 0.1)]\n",
        "#   selected_labels = labels[torch.where(labels > 0.1)]\n",
        "#   selected_output = torch.transpose(selected_output, 0, 1)\n",
        "#   return loss_function(selected_output, selected_labels)\n",
        "def my_dice_loss(preds, labels):\n",
        "  smooth = 1\n",
        "  dice = 2 * (torch.mul(pred, labels)).sum(dim=0).sum(dim=0).sum(dim=0) / ((pred.pow(2) + labels.pow(2)).sum(dim=0).sum(dim=0).sum(dim=0) + smooth)\n",
        "  return torch.clamp((1 - dice).mean(), 0, 1)\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        \n",
        "        # pred.shape is [batch_size,1,1,512,512], target.shape is [batch_size,1,512,512]\n",
        "        pred = pred.squeeze(dim=1)\n",
        "\n",
        "        smooth = 1\n",
        "\n",
        "        # dice\n",
        "        dice = 2 * torch.sum(torch.mul(pred, target)) / (torch.sum(pred.pow(2)) +\n",
        "                                            torch.sum(target.pow(2)) + smooth)\n",
        "\n",
        "        # 返回的是dice距离,torch.clamp(input, min, max, out=None),讲张量截断在[0,1]区间里 \n",
        "        return torch.clamp((1 - dice).mean(), 0, 1)\n",
        "\n",
        "# loss_function = DiceLoss()"
      ],
      "metadata": {
        "id": "bnRe1Ntbww1b"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over epochs\n",
        "num_epochs = 15\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n",
        "best_acc = 0.0\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "epoch = 0\n",
        "for e in tqdm(range(num_epochs)):\n",
        "  # set the model in training mode\n",
        "  unet.train()\n",
        "  # initialize the total training and validation loss\n",
        "  total_train_loss = 0\n",
        "  total_test_loss = 0\n",
        "  # loop over the training set\n",
        "  with torch.set_grad_enabled(True):\n",
        "    train_acc = 0\n",
        "    test_acc = 0\n",
        "    for i, map in enumerate(trainLoader):\n",
        "      # send the input to the device\n",
        "      x, y = map['image'].to(device), map['label'].to(device).squeeze()\n",
        "      # perform a forward pass and calculate the training loss\n",
        "      prob = unet(x)\n",
        "      _, preds = torch.max(prob, 1)\n",
        "      loss = loss_function(prob, y)\n",
        "      # loss = my_dice_loss(preds, y)\n",
        "      # first, zero out any previously accumulated gradients, then\n",
        "      # perform backpropagation, and then update model parameters\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      # add the loss to the total training loss so far\n",
        "      total_train_loss += loss\n",
        "      train_acc += torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])\n",
        "  # switch off autograd\n",
        "  with torch.set_grad_enabled(False):\n",
        "    # set the model in evaluation mode\n",
        "    unet.eval()\n",
        "    # loop over the validation set\n",
        "    for map in testLoader:\n",
        "      # send the input to the device\n",
        "      x, y = map['image'].to(device), map['label'].to(device).squeeze()\n",
        "      # make the predictions and calculate the validation loss\n",
        "      prob = unet(x)\n",
        "      _, preds = torch.max(prob, 1)\n",
        "      total_test_loss += loss_function(prob, y)\n",
        "      # total_test_loss += my_dice_loss(preds, y)\n",
        "      test_acc += torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])\n",
        "  # calculate the average training and validation loss\n",
        "  avg_train_loss = total_train_loss / train_steps\n",
        "  avg_test_loss = total_test_loss / test_steps\n",
        "  train_acc /= train_steps\n",
        "  test_acc /= test_steps\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    best_model_wts = copy.deepcopy(unet.state_dict())\n",
        "    epoch = e\n",
        "  train_loss_history.append(avg_test_loss)\n",
        "  val_loss_history.append(avg_test_loss)\n",
        "  # update our training history\n",
        "  # H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
        "  # H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
        "  # print the model training and validation information\n",
        "  print(\"[INFO] EPOCH: {}/{}\".format(e + 1, num_epochs))\n",
        "  print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
        "    avg_train_loss, avg_test_loss))\n",
        "  print(\"Train acc: {:.6f}, Test acc: {:.4f}\".format(\n",
        "    train_acc, test_acc))\n",
        "# display the total time needed to perform the training\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "  endTime - startTime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeyvWtHu4A2g",
        "outputId": "66093eaf-e155-46be-e43e-cd4bc5cbc524"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training the network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1/30 [01:17<37:36, 77.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 1/30\n",
            "Train loss: 499531.312500, Test loss: 522729.2188\n",
            "Train acc: 0.907194, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [01:29<18:06, 38.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 2/30\n",
            "Train loss: 471396.500000, Test loss: 524583.3750\n",
            "Train acc: 0.914518, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [01:40<11:43, 26.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 3/30\n",
            "Train loss: 445088.875000, Test loss: 527134.5625\n",
            "Train acc: 0.927342, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [01:50<08:37, 19.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 4/30\n",
            "Train loss: 425901.375000, Test loss: 527619.1250\n",
            "Train acc: 0.946223, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [02:01<06:55, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 5/30\n",
            "Train loss: 417697.437500, Test loss: 528701.6875\n",
            "Train acc: 0.958961, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [02:12<05:50, 14.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 6/30\n",
            "Train loss: 411281.468750, Test loss: 528861.3750\n",
            "Train acc: 0.963854, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [02:23<05:08, 13.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 7/30\n",
            "Train loss: 406116.500000, Test loss: 529020.2500\n",
            "Train acc: 0.965217, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [02:33<04:35, 12.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 8/30\n",
            "Train loss: 400427.031250, Test loss: 529548.2500\n",
            "Train acc: 0.967277, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [02:44<04:10, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 9/30\n",
            "Train loss: 395577.156250, Test loss: 530050.8750\n",
            "Train acc: 0.967621, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [02:54<03:50, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 10/30\n",
            "Train loss: 390365.062500, Test loss: 530288.3750\n",
            "Train acc: 0.968156, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [03:05<03:35, 11.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 11/30\n",
            "Train loss: 385080.500000, Test loss: 529538.7500\n",
            "Train acc: 0.967928, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [03:16<03:21, 11.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 12/30\n",
            "Train loss: 379985.718750, Test loss: 530877.7500\n",
            "Train acc: 0.968326, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 13/30 [03:27<03:07, 11.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 13/30\n",
            "Train loss: 375225.562500, Test loss: 533580.9375\n",
            "Train acc: 0.968333, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 14/30 [03:38<02:55, 10.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 14/30\n",
            "Train loss: 369903.718750, Test loss: 536406.4375\n",
            "Train acc: 0.968538, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 15/30 [03:48<02:43, 10.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 15/30\n",
            "Train loss: 365716.312500, Test loss: 535739.0000\n",
            "Train acc: 0.968237, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [03:59<02:32, 10.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 16/30\n",
            "Train loss: 361630.625000, Test loss: 536199.7500\n",
            "Train acc: 0.968291, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 57%|█████▋    | 17/30 [04:10<02:21, 10.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 17/30\n",
            "Train loss: 358143.781250, Test loss: 534937.3125\n",
            "Train acc: 0.967899, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 60%|██████    | 18/30 [04:21<02:11, 10.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 18/30\n",
            "Train loss: 354668.187500, Test loss: 536938.0625\n",
            "Train acc: 0.967326, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    self._shutdown_workers()\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 63%|██████▎   | 19/30 [04:32<02:00, 10.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 19/30\n",
            "Train loss: 350924.500000, Test loss: 536352.2500\n",
            "Train acc: 0.967498, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 67%|██████▋   | 20/30 [04:43<01:50, 11.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 20/30\n",
            "Train loss: 348141.437500, Test loss: 536619.2500\n",
            "Train acc: 0.966580, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "AssertionError: can only test a child process\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 70%|███████   | 21/30 [04:55<01:39, 11.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 21/30\n",
            "Train loss: 345078.156250, Test loss: 535921.4375\n",
            "Train acc: 0.965474, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    self._shutdown_workers()\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 73%|███████▎  | 22/30 [05:06<01:30, 11.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 22/30\n",
            "Train loss: 341360.218750, Test loss: 537951.2500\n",
            "Train acc: 0.966546, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Traceback (most recent call last):\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "AssertionError: can only test a child process\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 77%|███████▋  | 23/30 [05:17<01:18, 11.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 23/30\n",
            "Train loss: 338288.593750, Test loss: 525769.6250\n",
            "Train acc: 0.965738, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "AssertionError: can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4d33774680>\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            " 80%|████████  | 24/30 [05:28<01:06, 11.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 24/30\n",
            "Train loss: 335817.406250, Test loss: 527087.4375\n",
            "Train acc: 0.965184, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 25/30 [05:39<00:54, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 25/30\n",
            "Train loss: 332932.406250, Test loss: 526483.3125\n",
            "Train acc: 0.965020, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 26/30 [05:50<00:43, 10.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 26/30\n",
            "Train loss: 330105.625000, Test loss: 527394.8750\n",
            "Train acc: 0.964632, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 27/30 [06:01<00:32, 10.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 27/30\n",
            "Train loss: 327364.406250, Test loss: 522276.0000\n",
            "Train acc: 0.964417, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [06:11<00:21, 10.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 28/30\n",
            "Train loss: 325165.687500, Test loss: 519017.3438\n",
            "Train acc: 0.964001, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 29/30 [06:22<00:10, 10.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 29/30\n",
            "Train loss: 322398.031250, Test loss: 523728.5625\n",
            "Train acc: 0.964468, Test acc: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [06:33<00:00, 13.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 30/30\n",
            "Train loss: 319513.718750, Test loss: 518585.5000\n",
            "Train acc: 0.964395, Test acc: 0.9864\n",
            "[INFO] total time taken to train the model: 393.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(preds == y) / (y.shape[0] * y.shape[1] * y.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpjvecU_cf3O",
        "outputId": "b92d4c0a-4ba4-47b0-e228-341b9a2635df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8088, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = './models'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(best_model_wts, os.path.join(save_dir, 'weights_best_val_acc.pt'))\n",
        "torch.save(unet.state_dict(), os.path.join(save_dir, 'weights_last.pt'.format(epoch)))"
      ],
      "metadata": {
        "id": "KPDuXrcIUZUY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{git_token}@github.com/{username}/{repository} temp\n",
        "%cp -rf models temp/models2\n",
        "%cd temp\n",
        "\n",
        "!git config --global user.email \"qzlinqian@126.com\"\n",
        "!git config --global user.name \"Qian Lin\"\n",
        "\n",
        "!git add .\n",
        "!git commit -m\"add 2d model v2\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9drqK8bd50S",
        "outputId": "c01a68e0-622b-453a-f922-4429cfad1777"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 35 (delta 11), reused 15 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "/content/temp\n",
            "[main f5e8bae] add 2d model v2\n",
            " 2 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 models2/weights_best_val_acc.pt\n",
            " create mode 100644 models2/weights_last.pt\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 226.19 KiB | 14.14 MiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/qzlinqian/6_869_project_med_seg\n",
            "   3851a4f..f5e8bae  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%rm -rf temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCYeGUP5f3kc",
        "outputId": "dbcbbdf4-6548-46b8-f014-685d98c9e508"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "r3548tMFFFY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vis_index = 0\n",
        "vis_image_path = training_imgs_dir + '/liver_' + str(vis_index) + '.nii.gz'\n",
        "vis_label_path = training_labels_dir + '/liver_' + str(vis_index) + '.nii.gz'\n",
        "vis_images = nib.load(vis_image_path).get_fdata().squeeze()\n",
        "vis_labels = nib.load(vis_label_path).get_fdata().squeeze()\n",
        "vis_pred = np.zeros(vis_labels.shape)"
      ],
      "metadata": {
        "id": "TJR4LVZijpWA"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(vis_labels.shape[2]):\n",
        "  x = torch.from_numpy(vis_images[:,:,i].squeeze()).float().unsqueeze(dim=0).unsqueeze(dim=0).to(device)\n",
        "  prob = unet(x)\n",
        "  _, pred = torch.max(prob, 1)\n",
        "  vis_pred[:,:,i] = pred.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "enW5ebMmnLop"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.sum(vis_pred == vis_labels) / vis_labels.shape[0] / vis_labels.shape[1] / vis_labels.shape[2]\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P__w23VLuAab",
        "outputId": "b4591433-f3ca-4f3c-eff9-e112430ea407"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9718919372558594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import matplotlib.animation as animate\n",
        "%matplotlib inline\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from cv2 import imread, createCLAHE # read and equalize images\n",
        "from glob import glob\n",
        "import h5py\n",
        "# for display the MRI images in animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def create_gif(input_image, title='.gif', filename='test.gif'):\n",
        "    # see example from matplotlib documentation\n",
        "    images = []\n",
        "    fig = plt.figure()\n",
        "    for i in range(input_image.shape[2]):\n",
        "        im = plt.imshow(input_image[:,:,i], animated=True)\n",
        "        images.append([im])\n",
        "    ani = animate.ArtistAnimation(fig, images, interval=50, blit=True, repeat_delay=1000)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.axis('off')\n",
        "    plt.close()\n",
        "    return ani"
      ],
      "metadata": {
        "id": "Lbw7JZTHsluS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_result(input_image, label, pred_label, title='.gif', filename='test.gif'):\n",
        "    # see example from matplotlib documentation\n",
        "    images = []\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "    for i in range(input_image.shape[2]):\n",
        "        x11, y11 = np.where(label[:,:,i] == 1)\n",
        "        x12, y12 = np.where(label[:,:,i] == 2)\n",
        "        x21, y21 = np.where(pred_label[:,:,i] == 1)\n",
        "        x22, y22 = np.where(pred_label[:,:,i] == 2)\n",
        "        im1 = ax1.imshow(input_image[:,:,i], animated=True)\n",
        "        ax1.scatter(x11, y11, color='y')\n",
        "        ax1.scatter(x12, y12, color='b')\n",
        "        im2 = ax2.imshow(input_image[:,:,i], animated=True)\n",
        "        ax2.scatter(x21, y21, color='y')\n",
        "        ax2.scatter(x22, y22, color='b')\n",
        "        images.append([im1, im2])\n",
        "    ani = animate.ArtistAnimation(fig, images, interval=50, blit=True, repeat_delay=1000)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.axis('off')\n",
        "    plt.close()\n",
        "    return ani\n",
        "\n",
        "ani = display_result(vis_images, vis_labels, vis_pred)\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "id": "UdP0VHgylK9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ani.save('./mymovie.mp4')"
      ],
      "metadata": {
        "id": "5xILnlZCsClS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ani = create_gif(vis_images, title='image', filename='image.gif')\n",
        "ani.save('./input.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "id": "B1URpq9Sssmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ani = create_gif(vis_labels, title='label', filename='label.gif')\n",
        "ani.save('./labels.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "id": "4htowo_UtAw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ani = create_gif(vis_pred, title='prediction', filename='prediction.gif')\n",
        "ani.save('./predictions.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "id": "pgPCPtnJtbPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis_pred[:,:,100].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RhCGdrpu3PV",
        "outputId": "7ef4c487-3b70-4399-e624-2f388d57d5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ]
}